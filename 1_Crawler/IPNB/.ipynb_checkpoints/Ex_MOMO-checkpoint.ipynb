{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ex_MOMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://m.momoshop.com.tw/search.momo?searchKeyword=羅技&couponSeq=&searchType=1&cateLevel=-1&cateCode=-1&ent=k&_imgSH=fourCardStyle', 'https://m.momoshop.com.tw/search.momo?searchKeyword=羅技&couponSeq=&searchType=1&cateLevel=-1&cateCode=-1&ent=k&_imgSH=fourCardStyle']\n",
      "Crawing No.1 Item in Total:40Item\n",
      "Crawing No.2 Item in Total:40Item\n",
      "Crawing No.3 Item in Total:40Item\n",
      "Crawing No.4 Item in Total:40Item\n",
      "Crawing No.5 Item in Total:40Item\n",
      "Crawing No.6 Item in Total:40Item\n",
      "Crawing No.7 Item in Total:40Item\n",
      "Crawing No.8 Item in Total:40Item\n",
      "Crawing No.9 Item in Total:40Item\n",
      "Crawing No.10 Item in Total:40Item\n",
      "Crawing No.11 Item in Total:40Item\n",
      "Crawing No.12 Item in Total:40Item\n",
      "Crawing No.13 Item in Total:40Item\n",
      "Crawing No.14 Item in Total:40Item\n",
      "Crawing No.15 Item in Total:40Item\n",
      "Crawing No.16 Item in Total:40Item\n",
      "Crawing No.17 Item in Total:40Item\n",
      "Crawing No.18 Item in Total:40Item\n",
      "Crawing No.19 Item in Total:40Item\n",
      "Crawing No.20 Item in Total:40Item\n",
      "Crawing No.21 Item in Total:40Item\n",
      "Crawing No.22 Item in Total:40Item\n",
      "Crawing No.23 Item in Total:40Item\n",
      "Crawing No.24 Item in Total:40Item\n",
      "Crawing No.25 Item in Total:40Item\n",
      "Crawing No.26 Item in Total:40Item\n",
      "Crawing No.27 Item in Total:40Item\n",
      "Crawing No.28 Item in Total:40Item\n",
      "Crawing No.29 Item in Total:40Item\n",
      "Crawing No.30 Item in Total:40Item\n",
      "Crawing No.31 Item in Total:40Item\n",
      "Crawing No.32 Item in Total:40Item\n",
      "Crawing No.33 Item in Total:40Item\n",
      "Crawing No.34 Item in Total:40Item\n",
      "Crawing No.35 Item in Total:40Item\n",
      "Crawing No.36 Item in Total:40Item\n",
      "Crawing No.37 Item in Total:40Item\n",
      "Crawing No.38 Item in Total:40Item\n",
      "Crawing No.39 Item in Total:40Item\n",
      "Crawing No.40 Item in Total:40Item\n"
     ]
    }
   ],
   "source": [
    "import re, time, requests, csv\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "#解析(MoMo要用headers)\n",
    "def get_soup(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Mobile Safari/537.36\"}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    return BeautifulSoup(res.text, 'lxml')\n",
    "\n",
    "#搜尋網址&換頁\n",
    "def get_urls(url, query, start_page, end_page): \n",
    "    urls = []\n",
    "    \n",
    "    for page in range(start_page, end_page+1):\n",
    "        urls.append(url.format(query, page))    #query帶入url的{0}、page帶入{1}\n",
    "    print(urls)    \n",
    "    return urls\n",
    "\n",
    "# 依序爬取每頁點入網址\n",
    "def FindLinks(pages):\n",
    "    linklist = []\n",
    "    for page in pages:  \n",
    "        soup = get_soup(page)\n",
    "        links = soup.find_all('li', \"goodsItemLi\")\n",
    "        for link in links:\n",
    "            k = \"https://m.momoshop.com.tw\" + link.find(\"a\").get('href')\n",
    "            linklist.append(k)\n",
    "    return linklist\n",
    "\n",
    "# 爬取點入分頁資料\n",
    "def get_goods(url):\n",
    "    goods = []\n",
    "    rows = get_soup(url)\n",
    "\n",
    "    for row in rows:\n",
    "\n",
    "        try:\n",
    "            name = row.find('h2', attrs={'id' : 'goodsName'}).text\n",
    "        except:\n",
    "            name = None\n",
    "\n",
    "        try:\n",
    "            price = row.find('table', 'prdDetail bookDetail').td.text\n",
    "        except:\n",
    "            price = None\n",
    "            \n",
    "        try:\n",
    "            Sale_price = row.find(\"td\", class_=\"priceTxtArea\").text\n",
    "        except:\n",
    "            Sale_price = None\n",
    "            \n",
    "        try:\n",
    "            URL = url\n",
    "        except:\n",
    "            URL = None\n",
    "            \n",
    "        good= [name, price, Sale_price, URL]\n",
    "        goods.append(good)\n",
    "        \n",
    "    return goods[1]  #因為不知為何第[0]列都會出現一排None，只好取第[1]列\n",
    "\n",
    "# 將每一個點入頁面的List依序爬取\n",
    "def scraping(urls):\n",
    "    all_goods = [[\"name\",\"price\",\"Sale_price\",\"URL\"]]\n",
    "    \n",
    "    for idx,i in enumerate(FindLinks(urls)):  #記錄目前進行的迴圈次數，配上總迴圈次數，可做為進度條使用。\n",
    "        print(\"Crawing No.\" + str(idx+1) + \" Item in Total:\" + str(len(FindLinks(urls))) + \"Item\")\n",
    "        \n",
    "        goods = get_goods(i)\n",
    "        time.sleep(0.2)\n",
    "        all_goods.append(goods)\n",
    "    return all_goods\n",
    "#存成CSV\n",
    "def save_to_csv(items, file):\n",
    "    with open(file, \"w+\", newline=\"\", encoding=\"utf_8_sig\") as fp:  #utf_8_sig:能讓輸出的csv正確顯示中文(utf_8會有亂碼)\n",
    "        writer = csv.writer(fp)\n",
    "        for item in items:\n",
    "            writer.writerow(item)\n",
    "    \n",
    "# 開始爬蟲\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"在電腦周邊中搜尋\"\"\"\n",
    "    url = \"https://m.momoshop.com.tw/search.momo?searchKeyword={0}&couponSeq=&searchType=1&cateLevel=-1&cateCode=-1&ent=k&_imgSH=fourCardStyle\"\n",
    "    \n",
    "    urls = get_urls(url, \"羅技\", 0, 1)\n",
    "    \n",
    "    m = scraping(urls)\n",
    "    save_to_csv(m, \"m.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
