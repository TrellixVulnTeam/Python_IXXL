{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原文網址:\n",
    "https://tlyu0419.github.io/2019/05/01/Crawl-Facebook/#more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, time, requests\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def FindLinks(url, n):\n",
    "    Links = []\n",
    "    driver.get(url)\n",
    "    for i in range(n):\n",
    "        time.sleep(2)\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    # 這裡會跳出要我們登入的大畫面，找到「稍後再說」的按鈕並點擊\n",
    "    driver.find_element_by_xpath('//a[@id=\"expanding_cta_close_button\"]').click()\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    posts = soup.findAll('div', {'class':'clearfix y_c3pyo2ta3'})\n",
    "    for i in posts:\n",
    "        Links.append('https://www.facebook.com' + i.find('a',{'class':'_5pcq'}).attrs['href'].split('?',2)[0])\n",
    "    return Links\n",
    "\n",
    "def expand(url):\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//a[@lang=\"en_US\"]').click()\n",
    "    except:\n",
    "        print(\"Now is in EN_US\")\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    # 點擊「comments」，藉以展開留言\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//div[@class=\"_5pcr userContentWrapper\"]//a[@data-testid=\"UFI2CommentsCount/root\"]').click()\n",
    "        time.sleep(1)\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(1)\n",
    "        driver.find_element_by_id('expanding_cta_close_button').click() \n",
    "    except:\n",
    "        print('There is no comment!')\n",
    "    k = 1\n",
    "    while k != 0:\n",
    "        k = 0\n",
    "        for i in driver.find_elements_by_xpath('//div[@class=\"_5pcr userContentWrapper\"]//div[@data-testid=\"UFI2CommentsList/root_depth_0\"]//a[@role=\"button\"]'): \n",
    "            # 反覆偵測是否有「看更多留言」、「看更多回覆」與「看完整貼文內容」等按鈕，若有擇點擊\n",
    "            if bool(re.search('comment|More|Repl',i.text)) == True :\n",
    "                driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "                time.sleep(2)\n",
    "                try:\n",
    "                    driver.find_element_by_xpath('//div[@style=\"display: block;\"]//a[@id=\"expanding_cta_close_button\"]').click()\n",
    "                except:\n",
    "                    print('No pupup!')\n",
    "                try:\n",
    "                    i.click()\n",
    "                except:\n",
    "                    print('Nothing')\n",
    "                time.sleep(2)\n",
    "                k += 1\n",
    "\n",
    "# 文章內容與互動摘要\n",
    "def PostContent(soup):\n",
    "    # po文區塊\n",
    "    userContent = soup.find('div', {'class':'_5pcr userContentWrapper'})\n",
    "    # po文人資訊區塊\n",
    "    PosterInfo = userContent.find('div', {'class':'l_c3pyo2v0u i_c3pynyi2f clearfix'})\n",
    "    # 互動摘要區(讚、留言與分享)\n",
    "    feedback = soup.find('form', {'class':'commentable_item collapsed_comments'})\n",
    "    # 名稱\n",
    "    Name = PosterInfo.find('img').attrs['aria-label']\n",
    "    # ID\n",
    "    ID = PosterInfo.find('a', {'class':'_5pb8 o_c3pynyi2g _8o _8s lfloat _ohe'}).attrs['href'].split('/?',2)[0].split('/',-1)[-1]\n",
    "    # 網址\n",
    "    Link = driver.current_url\n",
    "    # 發文時間\n",
    "    try:\n",
    "        Time = PosterInfo.find('abbr').attrs['title']\n",
    "    except:\n",
    "        Time = PosterInfo.find('div', {'class':'_1atc fsm fwn fcg'}).text\n",
    "    # 文章內容\n",
    "    try:\n",
    "        Content = userContent.find('div', {'class':'_5pbx userContent _3576'}).text\n",
    "    except:\n",
    "        Content = \"\"\n",
    "    # Like\n",
    "    try:\n",
    "        Like = feedback.find('span', {'data-testid':'UFI2TopReactions/tooltip_LIKE'}).find('a').attrs['aria-label']\n",
    "    except:\n",
    "        Like = '0' \n",
    "    # Angry\n",
    "    try:\n",
    "        ANGER = feedback.find('span', {'data-testid':'UFI2TopReactions/tooltip_ANGER'}).find('a').attrs['aria-label']\n",
    "    except:\n",
    "        ANGER = '0'\n",
    "    # HAHA\n",
    "    try:\n",
    "        HAHA = feedback.find('span', {'data-testid':'UFI2TopReactions/tooltip_HAHA'}).find('a').attrs['aria-label']\n",
    "    except:\n",
    "        HAHA = '0'\n",
    "    # 留言\n",
    "    try:\n",
    "        commentcount = feedback.find('a', {'data-testid':'UFI2CommentsCount/root'}).text\n",
    "    except:\n",
    "        commentcount = '0' \n",
    "    # 分享\n",
    "    try:\n",
    "        share = feedback.find('span', {'class':'_355t _4vn2'}).text\n",
    "    except:\n",
    "        share = '0' \n",
    "    return pd.DataFrame(\n",
    "        data = [{'Name':Name,\n",
    "                 'ID':ID,\n",
    "                 'Link':Link,\n",
    "                 'Time':Time,\n",
    "                 'Content':Content,\n",
    "                 'Like':Like,\n",
    "                 'ANGER':ANGER,\n",
    "                 \"HAHA\":HAHA,\n",
    "                 'commentcount':commentcount,\n",
    "                 'share':share}],\n",
    "        columns = ['Name', 'ID', 'Time', 'Content', 'Like', 'ANGER', 'HAHA', 'commentcount', 'share', 'Link'])\n",
    "\n",
    "# 留言\n",
    "def CrawlComment(soup):\n",
    "    Comments = pd.DataFrame()\n",
    "    # po文區塊\n",
    "    userContent = soup.find('div', {'class':'_5pcr userContentWrapper'})\n",
    "    # 用戶留言區\n",
    "    userContent = soup.find('div', {'class':'_5pcr userContentWrapper'})\n",
    "    # 回應貼文的留言\n",
    "    for i in userContent.findAll('div', {'data-testid':'UFI2Comment/root_depth_0'}):\n",
    "        try:\n",
    "            CommentContent = i.find('span', {'dir':'ltr'}).text\n",
    "        except:\n",
    "            CommentContent = 'Sticker'\n",
    "        Comment = pd.DataFrame(data = [{'CommentID':i.find('a', {'class':' _3mf5 _3mg0'}).attrs['data-hovercard'].split('id=',2)[1],\n",
    "                                 'CommentName':i.find('img').attrs['alt'],\n",
    "                                 'CommentTime':i.find('abbr',{'class':'livetimestamp'}).attrs['data-tooltip-content'],\n",
    "                                 'CommentContent':CommentContent,\n",
    "                                 'Link':driver.current_url}],\n",
    "                        columns = ['CommentID', 'CommentName', 'CommentTime', 'CommentContent', 'Link'])\n",
    "        Comments = pd.concat([Comments, Comment], ignore_index=True)\n",
    "    \n",
    "    # 回應留言的留言\n",
    "    for i in userContent.findAll('div', {'data-testid':'UFI2Comment/root_depth_1'}):\n",
    "        try:\n",
    "            CommentContent = i.find('span', {'dir':'ltr'}).text\n",
    "        except:\n",
    "            CommentContent = 'Sticker'\n",
    "        Comment = pd.DataFrame(data = [{'CommentID':i.find('a', {'class':' _3mf5 _3mg1'}).attrs['data-hovercard'].split('id=',2)[1],\n",
    "                                 'CommentName':i.find('img').attrs['alt'],\n",
    "                                 'CommentTime':i.find('abbr',{'class':'livetimestamp'}).attrs['data-tooltip-content'],\n",
    "                                 'CommentContent':CommentContent,\n",
    "                                 'Link':driver.current_url}],\n",
    "                        columns = ['CommentID', 'CommentName', 'CommentTime', 'CommentContent', 'Link'])\n",
    "        Comments = pd.concat([Comments, Comment], ignore_index=True)        \n",
    "    return Comments\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "Links = FindLinks(url = 'https://facebook.com/taiwanmobile/',\n",
    "                  n = 20)\n",
    "Links\n",
    "\n",
    "# 抓下來所有留言\n",
    "PostsInformation = pd.DataFrame()\n",
    "PostsComments = pd.DataFrame()\n",
    "for i in Links:\n",
    "    print('Dealing with: ' + i)\n",
    "    try:\n",
    "        expand(i)\n",
    "        soup = BeautifulSoup(driver.page_source)\n",
    "        PostsInformation = pd.concat([PostsInformation, PostContent(soup)],ignore_index=True)\n",
    "        PostsComments = pd.concat([PostsComments, CrawlComment(soup)],ignore_index=True)\n",
    "    except:\n",
    "        print('Load Failed: ' + i)\n",
    "\n",
    "PostsInformation\n",
    "PostsComments\n",
    "\n",
    "PostsInformation.to_excel('C:/Users/TLYu0419/Desktop/PostsInformation.xlsx')\n",
    "PostsComments.to_excel('C:/Users/TLYu0419/Desktop/PostsComments.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
